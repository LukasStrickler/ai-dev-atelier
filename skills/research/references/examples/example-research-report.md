# Research Report: {Topic}

**Generated:** {Date}
**Evidence Cards:** {Count} approaches analyzed
**Papers Analyzed:** {Total count} papers
**Research Question:** {User's query or research objective}

## Executive Summary

{2-3 paragraph summary of findings, key recommendations, and rationale. Should provide a high-level overview that allows readers to understand the main conclusions without reading the full report. Emphasize broad coverage (5+ evidence cards) and conflict discussion.}

**Key Findings:**
- {Finding 1}
- {Finding 2}
- {Finding 3}
- {Finding 4 - e.g., "Conflicting evidence on {topic} - {Approach A} vs {Approach B}"}
- {Finding 5 - e.g., "5+ evidence cards covering diverse approaches from best practices to conflicts"}

**Primary Recommendation:** {Approach name} is recommended for {use case} because {brief rationale}. However, {alternative approach} may be preferable when {specific conditions}.

**Conflict Summary:** {Brief summary of key conflicts identified and how they are resolved in recommendations}

## Research Methodology

### Search Strategy

- **Primary Queries:** {List of main search queries used}
- **Databases Searched:** {OpenAlex, arXiv, PubMed, etc.}
- **Filters Applied:** {Year range, citation count, open access, etc.}
- **Search Tools Used:** {OpenAlex MCP, Paper-search MCP, built-in web search}
- **Total Papers Found:** {Number}

### Selection Criteria

**Inclusion Criteria:**
- {Criterion 1 - e.g., peer-reviewed papers}
- {Criterion 2 - e.g., highly cited works}
- {Criterion 3 - e.g., relevant to research question}

**Exclusion Criteria:**
- {Criterion 1 - e.g., off-topic papers}
- {Criterion 2 - e.g., low quality sources}
- {Criterion 3 - e.g., insufficient information}

**Papers Selected:** {Number} papers met inclusion criteria

### Approach Grouping Rationale

{Explanation of how papers were grouped into approaches}

- **Approach 1 ({Name}):** {Rationale for grouping - e.g., "Papers proposing Paxos-based consensus algorithms"}
- **Approach 2 ({Name}):** {Rationale for grouping}
- **Approach 3 ({Name}):** {Rationale for grouping}

**Grouping Method:** {Methodology used - e.g., "Grouped by consensus algorithm type, validated by reading abstracts and methodology sections"}

### Papers Analyzed

- **Total Papers:** {Number}
- **Time Range:** {Earliest year} - {Latest year}
- **Paper Types:** {Conference papers, journal articles, etc.}
- **Approaches Identified:** {Number} distinct approaches

## Approaches Compared

{One section per evidence card (approach)}

### Approach 1: {Approach Name}

**Overview:** {1-2 sentence overview of what this approach is}

**Papers Supporting This Approach:**
- {Paper 1 title} ({Year}) - {Brief note on contribution}
- {Paper 2 title} ({Year}) - {Brief note on contribution}
- {Paper 3 title} ({Year}) - {Brief note on contribution}
- See evidence card: `evidence-card-approach-1.md` for complete list

**Key Claims:**
- {Claim 1 from evidence card}
- {Claim 2 from evidence card}
- {Claim 3 from evidence card}

**Benefits:**
- {Benefit 1 - synthesized from evidence card}
- {Benefit 2}
- {Benefit 3}

**Negatives/Limitations:**
- {Limitation 1 - synthesized from evidence card}
- {Limitation 2}
- {Limitation 3}

**Tradeoffs:**
- {Tradeoff 1 - what you gain and lose}
- {Tradeoff 2}
- {Tradeoff 3}

**When to Use:**
- {Scenario 1 - conditions from evidence card}
- {Scenario 2}
- {Scenario 3}

**Evidence Card:** `evidence-card-approach-1.md`

---

### Approach 2: {Approach Name}

[Same structure as Approach 1]

---

### Approach 3: {Approach Name}

[Same structure as Approach 1]

## Comparative Analysis

### Strengths Comparison

| Approach | Primary Strength | Secondary Strength | Best For |
|----------|------------------|-------------------|----------|
| {Approach 1} | {Strength 1} | {Strength 2} | {Use case 1} |
| {Approach 2} | {Strength 1} | {Strength 2} | {Use case 2} |
| {Approach 3} | {Strength 1} | {Strength 2} | {Use case 3} |

### Limitations Comparison

| Approach | Primary Limitation | Secondary Limitation | When to Avoid |
|----------|---------------------|----------------------|---------------|
| {Approach 1} | {Limitation 1} | {Limitation 2} | {Scenario 1} |
| {Approach 2} | {Limitation 1} | {Limitation 2} | {Scenario 2} |
| {Approach 3} | {Limitation 1} | {Limitation 2} | {Scenario 3} |

### Best For Scenarios

| Scenario | Recommended Approach | Alternative | Reason |
|----------|---------------------|-------------|--------|
| {Scenario 1} | {Approach X} | {Approach Y} | {Reason} |
| {Scenario 2} | {Approach Y} | {Approach Z} | {Reason} |
| {Scenario 3} | {Approach Z} | {Approach X} | {Reason} |

### Performance Comparison

| Approach | Performance Characteristic | Tradeoff |
|----------|---------------------------|----------|
| {Approach 1} | {Performance metric} | {What you trade} |
| {Approach 2} | {Performance metric} | {What you trade} |
| {Approach 3} | {Performance metric} | {What you trade} |

## Evidence Summary

### Supporting Evidence

{Claims supported by evidence across approaches}

- **{Claim}**: Supported by {Paper 1}, {Paper 2} (see {Approach 1} evidence card)
- **{Claim}**: Supported by {Paper 3}, {Paper 4} (see {Approach 2} evidence card)
- **{Claim}**: Supported across all approaches (see all evidence cards)

### Conflicting Evidence

{Where approaches disagree or have contradictory findings. This section is critical - explicitly discuss conflicts and provide guidance on when each approach applies.}

**Key Conflicts Identified:**
- **{Claim/Area}**: {Approach 1} supports {position}, but {Approach 2} contradicts with {position}
  - **Context:** {Why they disagree, what conditions matter, what evidence supports each position}
  - **Resolution:** {How to reconcile or when each applies}
  - **Recommendation:** {Which approach to use under what conditions}

- **{Claim/Area}**: {Approach 2} and {Approach 3} have different findings
  - **Context:** {Why they differ, what conditions lead to different outcomes}
  - **Resolution:** {How to understand the difference, when each finding applies}
  - **Recommendation:** {Which approach to use under what conditions}

**Conflict Analysis:**
- **Areas of strong disagreement:** {List areas where approaches fundamentally conflict}
- **Areas of partial disagreement:** {List areas where approaches differ but can be reconciled}
- **Context-dependent differences:** {List areas where differences depend on specific conditions}

**Guidance for Resolving Conflicts:**
- **When to use {Approach 1}:** {Specific conditions, use cases, constraints}
- **When to use {Approach 2}:** {Specific conditions, use cases, constraints}
- **When to use {Approach 3}:** {Specific conditions, use cases, constraints}
- **Hybrid approaches:** {When multiple approaches can be combined or used together}

### Gaps in Research

{Areas where evidence is weak or missing}

- **{Area 1}**: Limited research, need more studies
  - **Impact:** {How this affects recommendations}
  - **Future Research:** {What studies would help}

- **{Area 2}**: Conflicting findings, unclear consensus
  - **Impact:** {How this affects recommendations}
  - **Future Research:** {What would clarify}

- **{Area 3}**: No research found on {topic}
  - **Impact:** {How this affects recommendations}
  - **Future Research:** {What studies are needed}

## Recommendations

### Primary Recommendation

**{Approach/Strategy Name}** is recommended for {general use case} because:

1. **{Reason 1}**: {Explanation with evidence from evidence card}
2. **{Reason 2}**: {Explanation with evidence from evidence card}
3. **{Reason 3}**: {Explanation with evidence from evidence card}

**Evidence:** See `evidence-card-approach-{N}.md` for supporting evidence.

**When to Use:**
- {Scenario 1}
- {Scenario 2}
- {Scenario 3}

### Alternative Recommendations

**For {specific scenario}:**
- **Use {Approach X}** because {reason with evidence}
- **Evidence:** See `evidence-card-approach-{N}.md`

**For {specific scenario}:**
- **Use {Approach Y}** because {reason with evidence}
- **Evidence:** See `evidence-card-approach-{N}.md`

**For {specific scenario}:**
- **Use {Approach Z}** because {reason with evidence}
- **Evidence:** See `evidence-card-approach-{N}.md`

### Implementation Considerations

**General Considerations:**
- {Consideration 1 - e.g., team expertise required}
- {Consideration 2 - e.g., infrastructure requirements}
- {Consideration 3 - e.g., operational complexity}

**For {Approach 1}:**
- {Implementation consideration 1}
- {Implementation consideration 2}

**For {Approach 2}:**
- {Implementation consideration 1}
- {Implementation consideration 2}

**For {Approach 3}:**
- {Implementation consideration 1}
- {Implementation consideration 2}

## Implementation Resources

{Resources found using search skill (Tavily, Context7) for practical implementation}

### Packages / Libraries

{List packages/libraries implementing each approach}

**For {Approach 1}:**
- {Package/library name} - {Brief description, link}
- {Package/library name} - {Brief description, link}

**For {Approach 2}:**
- {Package/library name} - {Brief description, link}
- {Package/library name} - {Brief description, link}

**For {Approach 3}:**
- {Package/library name} - {Brief description, link}
- {Package/library name} - {Brief description, link}

### Implementation Guides / Tutorials

{List blog posts, tutorials, and guides}

- {Title} - {URL} - {Brief description}
- {Title} - {URL} - {Brief description}

### Code Examples

{List code examples and repositories}

- {Example name} - {URL} - {Brief description}
- {Example name} - {URL} - {Brief description}

### Real-World Usage

{List real-world examples and case studies}

- {Example name} - {URL} - {Brief description}
- {Example name} - {URL} - {Brief description}

## Answer to Original Question

{This section explicitly ties findings back to the original research question/intent}

**Original Research Question:** {Research question from research-question.md}

**Answer:**

Based on the evidence gathered from {number} papers and implementation resources, **{Approach/Strategy Name}** is recommended for {original problem context} because:

1. **{Reason 1}**: {Explanation with evidence, tied to original problem}
2. **{Reason 2}**: {Explanation with evidence, tied to original problem}
3. **{Reason 3}**: {Explanation with evidence, tied to original problem}

**How This Addresses the Original Problem:**
- {How this approach solves the original problem}
- {How this approach meets the desired outcome}
- {How this approach fits within the constraints}

**Implementation Guidance:**
- {Practical steps to implement}
- {Packages/libraries to use}
- {Key considerations for implementation}

**Alternative Approaches:**
- For {specific scenario}: Consider {Alternative Approach} because {reason}
- For {specific scenario}: Consider {Alternative Approach} because {reason}

## References

### Papers Analyzed

{List all papers with metadata and approach links}

1. **{Paper Title}** ({Year})
   - Authors: {Author list}
   - DOI: {DOI}
   - URL: {Official URL}
   - Approach: {Approach name}
   - Evidence Card: `evidence-card-approach-{N}.md`

2. **{Paper Title}** ({Year})
   [Same structure]

{Continue for all papers...}

### Evidence Cards

- `evidence-card-approach-1.md` - {Approach 1 name} ({Number} papers)
- `evidence-card-approach-2.md` - {Approach 2 name} ({Number} papers)
- `evidence-card-approach-3.md` - {Approach 3 name} ({Number} papers)

### Search Queries Used

{List all search queries that led to papers}

- **Query 1:** "{query text}" ({Database}, {Number} results, found {papers})
- **Query 2:** "{query text}" ({Database}, {Number} results, found {papers})
- **Query 3:** "{query text}" ({Database}, {Number} results, found {papers})

## Appendix

### Related Topics

{Topics discovered during research that might be relevant for future research}

- {Topic 1}: {Brief description}
- {Topic 2}: {Brief description}
- {Topic 3}: {Brief description}

### Additional Notes

{Any additional observations, questions, or insights that don't fit in main sections}

### Future Research Directions

{Areas identified during research that need more study}

- {Area 1}: {Why it needs research}
- {Area 2}: {Why it needs research}

---

## Complete Example: Distributed Consensus Algorithms Research Report

# Research Report: Distributed Consensus Algorithms for Microservices

**Generated:** 2024-01-20
**Evidence Cards:** 5 approaches analyzed
**Papers Analyzed:** 18 papers, 7 non-academic sources
**Research Question:** Which distributed consensus algorithm should we implement for leader election in our Node.js microservices architecture, given our crash-fault tolerance requirements and small team size?

## Executive Summary

This research compared five consensus algorithm approaches (Paxos, Raft, PBFT, Alternative algorithms, and Hybrid approaches) to determine the best fit for our Node.js microservices architecture. Through analysis of 18 academic papers and 7 non-academic sources, we identified Raft as the primary recommendation due to its strong evidence base (7,000+ citations), excellent fit with our Node.js stack, and alignment with our team's need for simplicity.

**Key Findings:**
- Raft provides equivalent safety to Paxos with significantly better understandability
- PBFT offers Byzantine fault tolerance but is too complex for our use case
- Alternative algorithms show promise but lack sufficient validation
- Evidence strongly supports leader-based consensus for our crash-fault scenario
- 5+ evidence cards covering diverse approaches from best practices to conflicts

**Primary Recommendation:** **Raft consensus algorithm** is recommended for our Node.js microservices because it combines strong academic evidence (7,000+ citations) with practical fit (Node.js implementations available, team can understand it) and meets our constraints (crash-fault tolerance sufficient, performance requirements met). However, **Paxos** may be preferable if theoretical elegance is prioritized over implementation simplicity.

**Conflict Summary:** Main conflict is simplicity (Raft) vs theoretical elegance (Paxos). Evidence shows both provide equivalent safety, but Raft's understandability makes it better for our team. PBFT conflicts on fault model (Byzantine vs crash) - not needed for our use case.

## Research Methodology

### Search Strategy

- **Primary Queries:** 
  - "distributed consensus algorithms"
  - "Raft vs Paxos comparison"
  - "consensus algorithms for microservices"
  - "leader election algorithms"
  - "crash fault tolerance consensus"
- **Databases Searched:** OpenAlex, arXiv, IEEE Xplore, ACM Digital Library
- **Filters Applied:** Publication year 2013+ (Raft era), citation count 10+, peer-reviewed
- **Search Tools Used:** OpenAlex MCP, Paper-search MCP (arXiv, crossref), Tavily web search
- **Total Papers Found:** 25+ academic papers, 10+ non-academic sources

### Selection Criteria

**Inclusion Criteria:**
- Peer-reviewed papers on consensus algorithms
- Highly cited foundational papers (50+ citations)
- Recent papers (2020+) on consensus improvements
- Non-academic sources from authoritative sources (official docs, expert blogs)
- Relevant to crash-fault tolerance and leader election

**Exclusion Criteria:**
- Papers focusing only on Byzantine fault tolerance (not our use case)
- Papers without implementation details or practical guidance
- Very old papers (pre-2010) unless foundational

**Papers Selected:** 18 academic papers and 7 non-academic sources met inclusion criteria

### Approach Grouping Rationale

Papers were grouped by consensus algorithm type and design philosophy:

- **Approach 1 (Raft)**: Papers proposing Raft consensus algorithm (leader-based, designed for understandability)
- **Approach 2 (Paxos)**: Papers on Paxos and variants (foundational, theoretically elegant)
- **Approach 3 (PBFT)**: Papers on Byzantine fault-tolerant consensus (handles malicious nodes)
- **Approach 4 (Alternatives)**: Newer consensus algorithms with different approaches
- **Approach 5 (Conflicts)**: Papers debating tradeoffs and comparing approaches

**Grouping Method:** Grouped by algorithm type, validated by reading abstracts and methodology sections. Conflicting viewpoints grouped separately to enable comparison.

### Papers Analyzed

- **Total Papers:** 18 academic papers, 7 non-academic sources
- **Time Range:** 2013 - 2024
- **Paper Types:** Conference papers, journal articles, surveys, documentation
- **Approaches Identified:** 5 distinct approaches

## Approaches Compared

### Approach 1: Raft Consensus

**Overview:** Leader-based consensus algorithm designed for understandability while maintaining equivalent safety to Paxos.

**Papers Supporting This Approach:**
- "In Search of an Understandable Consensus Algorithm" (2013) - Foundational Raft paper, 7,000+ citations
- "Raft Refloated" (2020) - Safety improvements, 150+ citations
- "Raft Consensus Algorithm: A Comprehensive Survey" (2021) - Survey of variants
- See evidence card: `evidence-card-raft-consensus.md` for complete list

**Key Claims:**
- Raft provides equivalent safety guarantees to Paxos with simpler implementation
- Leader-based design improves understandability and maintainability
- Achieves consensus with O(n) messages per operation in normal case
- Handles leader failures through election mechanism

**Benefits:**
- Simplicity: Easier to understand and implement than Paxos
- Strong evidence: 7,000+ citations, multiple validation studies
- Production-proven: Used by etcd, Consul (widely deployed)
- Node.js support: Multiple implementations available (raft-js, etcd)

**Negatives/Limitations:**
- No Byzantine fault tolerance (crash-fault only)
- Requires majority for progress (cannot handle network partitions splitting majority)
- Leader bottleneck for high-throughput scenarios
- Still complex for teams without distributed systems experience

**Tradeoffs:**
- Simplicity vs. Fault tolerance: Easier to understand but doesn't handle Byzantine faults
- Leader-based vs. Peer-to-peer: Simpler coordination but single point of coordination
- Understandability vs. Theoretical elegance: Practical focus over mathematical elegance

**When to Use:**
- Crash-fault tolerance sufficient (no malicious nodes)
- Value simplicity and understandability
- Small to medium cluster sizes (3-10 nodes)
- Team needs to understand and maintain the algorithm
- ✅ **Fits our context**: Node.js stack, small team, crash-fault sufficient

**Evidence Card:** `evidence-card-raft-consensus.md`

### Approach 2: Paxos Consensus

**Overview:** Foundational consensus algorithm, theoretically elegant but complex to understand and implement.

**Papers Supporting This Approach:**
- "The Part-Time Parliament" (1998) - Original Paxos paper, foundational
- "Paxos Made Simple" (2001) - Simplified explanation, highly cited
- See evidence card: `evidence-card-paxos-consensus.md` for complete list

**Key Claims:**
- Theoretically elegant consensus algorithm
- Equivalent safety to Raft but more complex
- Well-established with extensive research

**Benefits:**
- Foundational: Established principles, extensive research
- Theoretically elegant: Mathematical foundation
- Strong evidence: Thousands of citations

**Negatives/Limitations:**
- Complexity: Hard to understand and implement correctly
- Less practical: Fewer production implementations
- Steeper learning curve for teams

**When to Use:**
- Theoretical elegance prioritized
- Team has strong distributed systems expertise
- Need peer-to-peer approach (no strong leader)

**Evidence Card:** `evidence-card-paxos-consensus.md`

### Approach 3: PBFT Consensus

**Overview:** Byzantine fault-tolerant consensus, handles malicious nodes but significantly more complex.

**Papers Supporting This Approach:**
- "Practical Byzantine Fault Tolerance" (1999) - Foundational PBFT paper
- See evidence card: `evidence-card-pbft-consensus.md` for complete list

**Key Claims:**
- Handles Byzantine faults (malicious nodes)
- More complex than crash-fault algorithms
- Higher message complexity

**Benefits:**
- Byzantine fault tolerance: Handles malicious nodes
- Strong security guarantees

**Negatives/Limitations:**
- High complexity: Much harder to understand and implement
- Higher message complexity: O(n²) messages
- Overkill for crash-fault scenarios

**When to Use:**
- Byzantine fault tolerance required
- Security-critical applications
- Large clusters with untrusted nodes

**Evidence Card:** `evidence-card-pbft-consensus.md`

## Comparative Analysis

### Strengths Comparison

| Approach | Primary Strength | Secondary Strength | Best For |
|----------|------------------|-------------------|----------|
| Raft | Understandability | Production-proven | Small-medium clusters, crash-fault |
| Paxos | Theoretical elegance | Foundational | Teams with strong distributed systems expertise |
| PBFT | Byzantine tolerance | Security | Security-critical, untrusted nodes |

### Limitations Comparison

| Approach | Primary Limitation | Secondary Limitation | When to Avoid |
|----------|---------------------|----------------------|---------------|
| Raft | No Byzantine tolerance | Leader bottleneck | Byzantine faults, very high throughput |
| Paxos | Complexity | Steep learning curve | Small teams, need quick implementation |
| PBFT | High complexity | Message overhead | Crash-fault scenarios, small teams |

### Best For Scenarios

| Scenario | Recommended Approach | Alternative | Reason |
|----------|---------------------|-------------|--------|
| Our use case (Node.js, small team, crash-fault) | Raft | Paxos | Simplicity + evidence + fit |
| Theoretical research | Paxos | Raft | Mathematical elegance |
| Security-critical, untrusted nodes | PBFT | Raft | Byzantine fault tolerance needed |

## Evidence Summary

### Supporting Evidence

- **Raft provides equivalent safety to Paxos**: Supported by "In Search of an Understandable Consensus Algorithm" (7,000+ citations), "Raft Refloated" (see Raft evidence card)
- **Raft is simpler to understand**: Supported by multiple papers comparing Raft to Paxos (see Raft evidence card)
- **Leader-based consensus works for crash-fault**: Supported across all leader-based approaches

### Conflicting Evidence

**Key Conflicts Identified:**

- **Simplicity vs. Theoretical Elegance**: Raft supports simplicity and understandability, but Paxos contradicts with emphasis on theoretical elegance
  - **Context:** Both provide equivalent safety, but differ in design philosophy
  - **Resolution:** For practical implementation (our case), Raft's simplicity matters more. For theoretical work, Paxos's elegance may be preferred.
  - **Recommendation:** Use Raft for our context (practical implementation, small team)

- **Crash-Fault vs. Byzantine Fault Tolerance**: Raft supports crash-fault model, but PBFT contradicts with Byzantine fault tolerance requirement
  - **Context:** Different failure models - crash-fault (Raft) vs. malicious nodes (PBFT)
  - **Resolution:** Our use case requires crash-fault only (no malicious nodes), so Raft's model fits. PBFT is overkill.
  - **Recommendation:** Use Raft (crash-fault sufficient), avoid PBFT (unnecessary complexity)

**Conflict Analysis:**
- **Areas of strong disagreement:** Fault model (crash vs Byzantine), design philosophy (simplicity vs elegance)
- **Areas of partial disagreement:** Implementation complexity (Raft simpler, but both complex)
- **Context-dependent differences:** Team expertise determines which complexity is acceptable

**Guidance for Resolving Conflicts:**
- **When to use Raft:** Crash-fault sufficient, value simplicity, small-medium teams, practical implementation
- **When to use Paxos:** Theoretical elegance prioritized, strong distributed systems expertise, peer-to-peer preferred
- **When to use PBFT:** Byzantine fault tolerance required, security-critical, untrusted nodes
- **Hybrid approaches:** Can use Raft for coordination, add Byzantine checks if needed later

## Recommendations

### Primary Recommendation

**Raft Consensus Algorithm** is recommended for our Node.js microservices architecture because:

1. **Strong Evidence**: 7,000+ citations in foundational paper, multiple validation studies, production-proven (etcd, Consul)
2. **Codebase Fit**: Node.js implementations available (raft-js), integrates with our stack, works with Kubernetes
3. **Team Fit**: Simpler than Paxos, team can understand and maintain it, good documentation available
4. **Meets Constraints**: Crash-fault tolerance sufficient, performance requirements met (<100ms), scalable to our needs

**Evidence:** See `evidence-card-raft-consensus.md` for supporting evidence.

**When to Use:**
- Crash-fault tolerance sufficient (our case)
- Small to medium teams (our case: 5 developers)
- Value simplicity and understandability (our case)
- Node.js/TypeScript stack (our case)

### Alternative Recommendations

**For teams with strong distributed systems expertise:**
- **Use Paxos** because theoretical elegance may be valued, and team can handle complexity
- **Evidence:** See `evidence-card-paxos-consensus.md`

**For security-critical applications with untrusted nodes:**
- **Use PBFT** because Byzantine fault tolerance is required
- **Evidence:** See `evidence-card-pbft-consensus.md`

**For experimental projects exploring new approaches:**
- **Consider Alternative algorithms** because they may offer SOTA features, but acknowledge lower evidence strength
- **Evidence:** See `evidence-card-alternative-consensus.md`

### Implementation Considerations

**General Considerations:**
- Team expertise: Raft requires distributed systems knowledge but is learnable
- Infrastructure: Need stable network, majority of servers available
- Monitoring: Implement logging and metrics for leader election and log replication

**For Raft:**
- Use existing library (etcd via gRPC or raft-js) rather than implementing from scratch
- Implement proper error handling for network partitions
- Set appropriate timeouts for leader election
- Monitor leader health and election events

## Implementation Resources

### Packages / Libraries

**For Raft:**
- **etcd** (Go, gRPC) - Production-grade, used by Kubernetes
- **raft-js** (JavaScript/TypeScript) - Node.js implementation, fits our stack
- **hashicorp/raft** (Go) - Well-documented library

### Implementation Guides / Tutorials

- etcd Raft documentation: https://etcd.io/docs/latest/learning/raft/
- Raft visualization: https://raft.github.io/ (interactive learning tool)

## Answer to Original Question

**Original Research Question:** "Which distributed consensus algorithm should we implement for leader election in our Node.js microservices architecture, given our crash-fault tolerance requirements and small team size?"

**Answer:**

Based on evidence from 18 papers and 7 non-academic sources, **Raft consensus algorithm** is recommended for our Node.js microservices architecture because:

1. **Strong Evidence**: Raft has 7,000+ citations in foundational paper, multiple validation studies, and is production-proven (etcd, Consul). This provides high confidence in its correctness and practicality.

2. **Codebase Fit**: Raft fits our Node.js stack with multiple implementation options (raft-js for direct integration, etcd via gRPC for production-grade solution). It integrates well with our Kubernetes deployment and existing infrastructure.

3. **Team Fit**: Raft's focus on understandability makes it suitable for our small team (5 developers). The algorithm is simpler than Paxos while maintaining equivalent safety, reducing implementation and maintenance burden.

4. **Meets Constraints**: Raft provides crash-fault tolerance (sufficient for our use case), meets performance requirements (<100ms leader election), and scales to our needs (3-10 instances, can scale to 20).

**How This Addresses the Original Problem:**
- Solves leader election coordination reliably (evidence-backed approach)
- Fits our technology stack (Node.js implementations available)
- Aligns with team capabilities (understandable, maintainable)
- Meets performance and scalability requirements

**Implementation Guidance:**
- **Short-term**: Use etcd via gRPC for production-grade Raft (recommended for reliability)
- **Alternative**: Use raft-js for direct Node.js integration (if prefer pure JavaScript)
- **Key considerations**: Implement proper error handling, monitoring, and timeout configuration
- **Next steps**: Prototype with etcd, measure performance, integrate with existing services

**Alternative Approaches:**
- For teams with strong distributed systems expertise: Consider Paxos for theoretical elegance
- For security-critical applications: Consider PBFT if Byzantine fault tolerance becomes necessary
- For experimental projects: Monitor alternative algorithms as they mature and gain validation

## References

### Papers Analyzed

1. **"In Search of an Understandable Consensus Algorithm"** (2013)
   - Authors: Diego Ongaro, John Ousterhout
   - DOI: 10.5555/2643634.2643666
   - URL: https://raft.github.io/raft.pdf
   - Approach: Raft Consensus
   - Evidence Card: `evidence-card-raft-consensus.md`
   - Citations: 7,000+

2. **"Raft Refloated: Do We Have Consensus?"** (2020)
   - Authors: Heidi Howard, et al.
   - DOI: 10.1145/3380787.3393681
   - URL: https://dl.acm.org/doi/10.1145/3380787.3393681
   - Approach: Raft Consensus
   - Evidence Card: `evidence-card-raft-consensus.md`
   - Citations: 150+

[Continue for all 18 papers...]

### Evidence Cards

- `evidence-card-raft-consensus.md` - Raft Consensus (3 papers, 2 non-academic sources)
- `evidence-card-paxos-consensus.md` - Paxos Consensus (4 papers)
- `evidence-card-pbft-consensus.md` - PBFT Consensus (2 papers)
- `evidence-card-alternative-consensus.md` - Alternative Algorithms (3 papers, 2 non-academic sources)
- `evidence-card-conflicts.md` - Conflicts and Tradeoffs (6 papers, 3 non-academic sources)

### Search Queries Used

- **Query 1:** "distributed consensus algorithms" (OpenAlex, 45 results, found 12 papers)
- **Query 2:** "Raft vs Paxos comparison" (Tavily, 8 results, found 3 non-academic sources)
- **Query 3:** "consensus algorithms for microservices" (OpenAlex, 28 results, found 6 papers)
[Continue for all queries...]
